Reading list for research topics in Vison Transformers.

We list the most popular methods for Vision Transformer, if I missed something, please submit a request.
(Note: We show the date of the first version of Arxiv here. But the link of paper is the lastest.)


# Supervied Vision Transformers as backbone models.

Data|Method|Conference|Title|Code
-----|----|-----|-----|-----
2020-10-22|ViT|ICLR 2021|[AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](https://arxiv.org/abs/2010.11929)|[ViT](https://github.com/google-research/vision_transformer)
2020-12-23|DeiT|ICML 2021|[Training data-efficient image transformers & distillation through attention](https://arxiv.org/pdf/2012.12877.pdf)|[DeiT](https://github.com/facebookresearch/deit)
2021-02-24|PVT|ICCV 2021|[Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions](https://arxiv.org/pdf/2102.12122.pdf)|[PVT](https://github.com/whai362/PVT)
2021-02-27|TNT|Arxiv 2021|[Transformer in Transformer](https://arxiv.org/pdf/2103.00112.pdf)|[TNT](https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/cv/TNT)
2021-03-25|Swin|ICCV 2021|[Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/pdf/2103.14030v2.pdf)|[Swin-Transformer](https://github.com/microsoft/Swin-Transformer)
2021-04-21|MViT|ICCV2021|[Multiscale Vision Transformers](https://arxiv.org/pdf/2104.11227.pdf)|[MViT](https:/github.com/facebookresearch/SlowFast)
2021-06-11|Twins|Arxiv 2021|[Twins: Revisiting the Design of Spatial Attention in Vision Transformers](https://arxiv.org/abs/2104.13840)|[Twins](https://github.com/Meituan-AutoML/Twins)
2021-12-02|MViT v2|Arxiv 2021|[Improved Multiscale Vision Transformers for Classification and Detection](https://arxiv.org/pdf/2112.01526.pdf)| None
updating......




# Self-supervied Vision Transformers as backbone models.
Data|Method|Conference|Title|Code
-----|----|-----|-----|-----
2021-11-11|MAE|Arxiv 2021|[Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/pdf/2111.06377.pdf)|[MAE](https://github.com/facebookresearch/mae)
2022-01-19|RePre|Arxiv 2022|[RePre: Improving Self-Supervised Vision Transformer with
Reconstructive Pre-training](https://arxiv.org/pdf/2111.06377.pdf)|None

Todo:Moco v3, BeiT,MaskFeat,iBoT,DINO

# Surveys

Data|Conference|Title|
-----|----|-----
2020-12-23 (latest version: 2021-08-12)|None|[A Survey on Vision Transformer](https://arxiv.org/pdf/2012.12556.pdf)
2021-01-04 (latest version: 2021-10-03)|None|[Transformers in vision: A survey](https://arxiv.org/pdf/2101.01169.pdf)


